# å¤šAgentåä½œæŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç» OpenManus-Go çš„å¤šAgentåä½œåŠŸèƒ½ï¼ŒåŒ…æ‹¬å·¥ä½œæµè®¾è®¡ã€ä»»åŠ¡ç¼–æ’å’Œåä½œæ¨¡å¼ã€‚

## ğŸ“‹ ç›®å½•

- [å¤šAgentæ¦‚è¿°](#å¤šagentæ¦‚è¿°)
- [å·¥ä½œæµæ¨¡å¼](#å·¥ä½œæµæ¨¡å¼)
- [ä»»åŠ¡ç¼–æ’](#ä»»åŠ¡ç¼–æ’)
- [Agentç±»å‹](#agentç±»å‹)
- [äº‹ä»¶ç³»ç»Ÿ](#äº‹ä»¶ç³»ç»Ÿ)
- [å®é™…åº”ç”¨](#å®é™…åº”ç”¨)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)

## ğŸŒŸ å¤šAgentæ¦‚è¿°

### ä»€ä¹ˆæ˜¯å¤šAgentåä½œï¼Ÿ

å¤šAgentåä½œæ˜¯æŒ‡å¤šä¸ªAI Agenté€šè¿‡åè°ƒå·¥ä½œæ¥å®Œæˆå¤æ‚ä»»åŠ¡çš„èƒ½åŠ›ã€‚æ¯ä¸ªAgentå¯ä»¥ï¼š

- ä¸“æ³¨äºç‰¹å®šé¢†åŸŸçš„ä»»åŠ¡
- å¹¶è¡Œæˆ–ä¸²è¡Œæ‰§è¡Œ
- å…±äº«æ•°æ®å’ŒçŠ¶æ€
- åŸºäºä¾èµ–å…³ç³»åè°ƒæ‰§è¡Œ

### åä½œä¼˜åŠ¿

- **ä»»åŠ¡åˆ†è§£**ï¼šå¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºç®€å•å­ä»»åŠ¡
- **ä¸“ä¸šåŒ–**ï¼šä¸åŒAgentä¸“æ³¨ä¸åŒé¢†åŸŸ
- **å¹¶è¡Œå¤„ç†**ï¼šæé«˜æ•´ä½“æ‰§è¡Œæ•ˆç‡
- **å®¹é”™æ€§**ï¼šå•ä¸ªAgentå¤±è´¥ä¸å½±å“æ•´ä½“
- **å¯æ‰©å±•æ€§**ï¼šæ˜“äºæ·»åŠ æ–°çš„Agentç±»å‹

### æ¶æ„å›¾

```mermaid
graph TB
    subgraph "å·¥ä½œæµå¼•æ“"
        Engine[Flow Engine]
        Scheduler[ä»»åŠ¡è°ƒåº¦å™¨]
        EventBus[äº‹ä»¶æ€»çº¿]
    end
    
    subgraph "Agentå·¥å‚"
        Factory[Agent Factory]
        General[é€šç”¨Agent]
        DataAnalyst[æ•°æ®åˆ†æAgent]
        WebScraper[ç½‘é¡µçˆ¬è™«Agent]
        FileProcessor[æ–‡ä»¶å¤„ç†Agent]
    end
    
    subgraph "å…±äº«èµ„æº"
        StateStore[çŠ¶æ€å­˜å‚¨]
        MessageQueue[æ¶ˆæ¯é˜Ÿåˆ—]
        ResultCache[ç»“æœç¼“å­˜]
    end
    
    Engine --> Scheduler
    Engine --> EventBus
    Scheduler --> Factory
    Factory --> General
    Factory --> DataAnalyst
    Factory --> WebScraper
    Factory --> FileProcessor
    
    General --> StateStore
    DataAnalyst --> MessageQueue
    WebScraper --> ResultCache
```

## ğŸ”„ å·¥ä½œæµæ¨¡å¼

OpenManus-Go æ”¯æŒä¸‰ç§ä¸»è¦çš„æ‰§è¡Œæ¨¡å¼ï¼š

### 1. Sequentialï¼ˆé¡ºåºæ‰§è¡Œï¼‰

ä»»åŠ¡æŒ‰é¡ºåºä¾æ¬¡æ‰§è¡Œï¼Œå‰ä¸€ä¸ªä»»åŠ¡å®Œæˆåæ‰å¼€å§‹ä¸‹ä¸€ä¸ªã€‚

```mermaid
graph LR
    A[ä»»åŠ¡1] --> B[ä»»åŠ¡2] --> C[ä»»åŠ¡3] --> D[ä»»åŠ¡4]
```

**é€‚ç”¨åœºæ™¯**ï¼š
- ä»»åŠ¡é—´æœ‰å¼ºä¾èµ–å…³ç³»
- éœ€è¦ä¸¥æ ¼çš„æ‰§è¡Œé¡ºåº
- èµ„æºæœ‰é™çš„ç¯å¢ƒ

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```bash
# å¯åŠ¨é¡ºåºå·¥ä½œæµ
./bin/openmanus flow --mode sequential --agents 3

# æˆ–ä½¿ç”¨é…ç½®æ–‡ä»¶
./bin/openmanus flow --workflow examples/sequential-flow.json
```

### 2. Parallelï¼ˆå¹¶è¡Œæ‰§è¡Œï¼‰

æ‰€æœ‰ä»»åŠ¡åŒæ—¶å¼€å§‹æ‰§è¡Œï¼Œå……åˆ†åˆ©ç”¨å¹¶å‘èƒ½åŠ›ã€‚

```mermaid
graph TB
    Start[å¼€å§‹] --> A[ä»»åŠ¡1]
    Start --> B[ä»»åŠ¡2]
    Start --> C[ä»»åŠ¡3]
    Start --> D[ä»»åŠ¡4]
    A --> End[ç»“æŸ]
    B --> End
    C --> End
    D --> End
```

**é€‚ç”¨åœºæ™¯**ï¼š
- ä»»åŠ¡é—´æ— ä¾èµ–å…³ç³»
- éœ€è¦å¿«é€Ÿå®Œæˆ
- èµ„æºå……è¶³çš„ç¯å¢ƒ

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```bash
# å¯åŠ¨å¹¶è¡Œå·¥ä½œæµ
./bin/openmanus flow --mode parallel --agents 4

# æ•°æ®åˆ†æå¹¶è¡Œå¤„ç†
./bin/openmanus flow --mode parallel --data-analysis
```

### 3. DAGï¼ˆæœ‰å‘æ— ç¯å›¾ï¼‰

åŸºäºä¾èµ–å…³ç³»çš„æ™ºèƒ½è°ƒåº¦ï¼Œæ”¯æŒå¤æ‚çš„ä»»åŠ¡ç¼–æ’ã€‚

```mermaid
graph TB
    A[æ•°æ®æ”¶é›†] --> C[æ•°æ®æ¸…æ´—]
    B[é…ç½®å‡†å¤‡] --> C
    C --> D[æ•°æ®åˆ†æ]
    C --> E[æ•°æ®éªŒè¯]
    D --> F[æŠ¥å‘Šç”Ÿæˆ]
    E --> F
    F --> G[ç»“æœå‘å¸ƒ]
```

**é€‚ç”¨åœºæ™¯**ï¼š
- å¤æ‚çš„ä¸šåŠ¡æµç¨‹
- éƒ¨åˆ†ä»»åŠ¡å¯å¹¶è¡Œ
- éœ€è¦æœ€ä¼˜æ‰§è¡Œè·¯å¾„

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```bash
# å¯åŠ¨DAGå·¥ä½œæµ
./bin/openmanus flow --mode dag --workflow examples/data-pipeline.json
```

## ğŸ¯ ä»»åŠ¡ç¼–æ’

### å·¥ä½œæµå®šä¹‰

#### JSON æ ¼å¼å®šä¹‰

```json
{
  "id": "data-processing-workflow",
  "name": "æ•°æ®å¤„ç†å·¥ä½œæµ",
  "description": "å®Œæ•´çš„æ•°æ®å¤„ç†æµæ°´çº¿",
  "mode": "dag",
  "tasks": [
    {
      "id": "collect",
      "name": "æ•°æ®æ”¶é›†",
      "agent_type": "web_scraper",
      "goal": "ä»æŒ‡å®šç½‘ç«™æ”¶é›†æ•°æ®",
      "dependencies": [],
      "timeout": "5m",
      "retry_count": 3,
      "input": {
        "urls": ["https://api.example.com/data"],
        "output_file": "raw_data.json"
      }
    },
    {
      "id": "clean",
      "name": "æ•°æ®æ¸…æ´—",
      "agent_type": "data_analysis",
      "goal": "æ¸…æ´—å’ŒéªŒè¯æ”¶é›†çš„æ•°æ®",
      "dependencies": ["collect"],
      "timeout": "10m",
      "input": {
        "input_file": "raw_data.json",
        "output_file": "clean_data.json"
      }
    },
    {
      "id": "analyze",
      "name": "æ•°æ®åˆ†æ",
      "agent_type": "data_analysis",
      "goal": "åˆ†ææ¸…æ´—åçš„æ•°æ®ï¼Œç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š",
      "dependencies": ["clean"],
      "timeout": "15m",
      "input": {
        "input_file": "clean_data.json",
        "analysis_type": "statistical"
      }
    },
    {
      "id": "report",
      "name": "æŠ¥å‘Šç”Ÿæˆ",
      "agent_type": "file_processor",
      "goal": "ç”Ÿæˆæœ€ç»ˆçš„åˆ†ææŠ¥å‘Š",
      "dependencies": ["analyze"],
      "timeout": "5m",
      "input": {
        "template": "report_template.md",
        "output_format": "pdf"
      }
    }
  ],
  "global_timeout": "30m",
  "max_concurrency": 3
}
```

#### ç¨‹åºåŒ–å®šä¹‰

```go
package main

import (
    "context"
    "openmanus-go/pkg/flow"
)

func createDataPipeline() *flow.Workflow {
    workflow := flow.NewWorkflow(
        "data-pipeline",
        "æ•°æ®å¤„ç†æµæ°´çº¿",
        flow.ExecutionModeDAG,
    )
    
    // ä»»åŠ¡1ï¼šæ•°æ®æ”¶é›†
    collectTask := flow.NewTask(
        "collect",
        "æ•°æ®æ”¶é›†",
        "web_scraper",
        "ä»å¤šä¸ªAPIæºæ”¶é›†åŸå§‹æ•°æ®",
    )
    collectTask.Timeout = time.Minute * 5
    collectTask.Input = map[string]any{
        "sources": []string{
            "https://api.source1.com/data",
            "https://api.source2.com/data",
        },
        "output_dir": "./raw_data",
    }
    
    // ä»»åŠ¡2ï¼šæ•°æ®æ¸…æ´—
    cleanTask := flow.NewTask(
        "clean",
        "æ•°æ®æ¸…æ´—",
        "data_analysis",
        "æ¸…æ´—åŸå§‹æ•°æ®ï¼Œå»é™¤æ— æ•ˆå’Œé‡å¤æ•°æ®",
    )
    cleanTask.Dependencies = []string{"collect"}
    cleanTask.Timeout = time.Minute * 10
    cleanTask.Input = map[string]any{
        "input_dir": "./raw_data",
        "output_file": "./processed/clean_data.json",
        "validation_rules": []string{
            "remove_duplicates",
            "validate_schema",
            "normalize_format",
        },
    }
    
    // ä»»åŠ¡3ï¼šæ•°æ®åˆ†æ
    analyzeTask := flow.NewTask(
        "analyze",
        "æ•°æ®åˆ†æ",
        "data_analysis",
        "æ‰§è¡Œç»Ÿè®¡åˆ†æå’Œè¶‹åŠ¿è¯†åˆ«",
    )
    analyzeTask.Dependencies = []string{"clean"}
    analyzeTask.Timeout = time.Minute * 15
    analyzeTask.Input = map[string]any{
        "input_file": "./processed/clean_data.json",
        "analysis_types": []string{
            "descriptive_statistics",
            "trend_analysis",
            "correlation_analysis",
        },
        "output_dir": "./analysis_results",
    }
    
    // ä»»åŠ¡4ï¼šæŠ¥å‘Šç”Ÿæˆ
    reportTask := flow.NewTask(
        "report",
        "æŠ¥å‘Šç”Ÿæˆ",
        "file_processor",
        "ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Šå’Œæ‘˜è¦",
    )
    reportTask.Dependencies = []string{"analyze"}
    reportTask.Timeout = time.Minute * 5
    reportTask.Input = map[string]any{
        "analysis_dir": "./analysis_results",
        "template": "./templates/report.md",
        "output_formats": []string{"pdf", "html"},
        "output_dir": "./final_reports",
    }
    
    // æ·»åŠ ä»»åŠ¡åˆ°å·¥ä½œæµ
    workflow.AddTask(collectTask)
    workflow.AddTask(cleanTask)
    workflow.AddTask(analyzeTask)
    workflow.AddTask(reportTask)
    
    return workflow
}
```

### ä¾èµ–å…³ç³»ç®¡ç†

```go
// å¤æ‚ä¾èµ–å…³ç³»ç¤ºä¾‹
func createComplexWorkflow() *flow.Workflow {
    workflow := flow.NewWorkflow("complex", "å¤æ‚å·¥ä½œæµ", flow.ExecutionModeDAG)
    
    // Aï¼šæ— ä¾èµ–ï¼Œå¯ç«‹å³æ‰§è¡Œ
    taskA := flow.NewTask("A", "åˆå§‹åŒ–", "general", "å‡†å¤‡ç¯å¢ƒå’Œé…ç½®")
    
    // Bï¼šä¾èµ–A
    taskB := flow.NewTask("B", "æ•°æ®è·å–", "web_scraper", "è·å–å¤–éƒ¨æ•°æ®")
    taskB.Dependencies = []string{"A"}
    
    // Cï¼šä¾èµ–A
    taskC := flow.NewTask("C", "é…ç½®éªŒè¯", "general", "éªŒè¯é…ç½®æœ‰æ•ˆæ€§")
    taskC.Dependencies = []string{"A"}
    
    // Dï¼šä¾èµ–Bå’ŒC
    taskD := flow.NewTask("D", "æ•°æ®å¤„ç†", "data_analysis", "å¤„ç†è·å–çš„æ•°æ®")
    taskD.Dependencies = []string{"B", "C"}
    
    // Eï¼šåªä¾èµ–B
    taskE := flow.NewTask("E", "æ•°æ®å¤‡ä»½", "file_processor", "å¤‡ä»½åŸå§‹æ•°æ®")
    taskE.Dependencies = []string{"B"}
    
    // Fï¼šä¾èµ–Då’ŒE
    taskF := flow.NewTask("F", "æœ€ç»ˆæŠ¥å‘Š", "file_processor", "ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
    taskF.Dependencies = []string{"D", "E"}
    
    workflow.AddTask(taskA)
    workflow.AddTask(taskB)
    workflow.AddTask(taskC)
    workflow.AddTask(taskD)
    workflow.AddTask(taskE)
    workflow.AddTask(taskF)
    
    return workflow
}
```

## ğŸ¤– Agentç±»å‹

### å†…ç½®Agentç±»å‹

#### 1. General Agentï¼ˆé€šç”¨ï¼‰
- **ç”¨é€”**ï¼šé€šç”¨ä»»åŠ¡å¤„ç†
- **ç‰¹ç‚¹**ï¼šçµæ´»æ€§é«˜ï¼Œå¯å¤„ç†å„ç§ç±»å‹ä»»åŠ¡
- **é€‚ç”¨åœºæ™¯**ï¼šç®€å•ä»»åŠ¡ã€åŸå‹å¼€å‘

```go
type GeneralAgentConfig struct {
    MaxSteps    int    `json:"max_steps"`
    Temperature float64 `json:"temperature"`
    Model       string  `json:"model"`
}
```

#### 2. Data Analysis Agentï¼ˆæ•°æ®åˆ†æï¼‰
- **ç”¨é€”**ï¼šæ•°æ®åˆ†æå’Œå¤„ç†
- **ç‰¹ç‚¹**ï¼šä¼˜åŒ–çš„æ•°æ®å¤„ç†æç¤ºè¯å’Œå·¥å…·é›†
- **é€‚ç”¨åœºæ™¯**ï¼šç»Ÿè®¡åˆ†æã€æ•°æ®æ¸…æ´—ã€æŠ¥è¡¨ç”Ÿæˆ

```go
type DataAnalysisAgentConfig struct {
    MaxSteps         int      `json:"max_steps"`
    AnalysisTypes    []string `json:"analysis_types"`
    OutputFormats    []string `json:"output_formats"`
    VisualizationLib string   `json:"visualization_lib"`
}
```

#### 3. Web Scraper Agentï¼ˆç½‘é¡µçˆ¬è™«ï¼‰
- **ç”¨é€”**ï¼šç½‘é¡µæ•°æ®æŠ“å–
- **ç‰¹ç‚¹**ï¼šä¸“é—¨çš„çˆ¬è™«ç­–ç•¥å’Œååçˆ¬è™«æœºåˆ¶
- **é€‚ç”¨åœºæ™¯**ï¼šæ•°æ®æ”¶é›†ã€ä»·æ ¼ç›‘æ§ã€å†…å®¹èšåˆ

```go
type WebScraperAgentConfig struct {
    MaxSteps      int           `json:"max_steps"`
    UserAgents    []string      `json:"user_agents"`
    RequestDelay  time.Duration `json:"request_delay"`
    MaxRetries    int           `json:"max_retries"`
    RespectRobots bool          `json:"respect_robots"`
}
```

#### 4. File Processor Agentï¼ˆæ–‡ä»¶å¤„ç†ï¼‰
- **ç”¨é€”**ï¼šæ–‡ä»¶å’Œæ–‡æ¡£å¤„ç†
- **ç‰¹ç‚¹**ï¼šæ”¯æŒå¤šç§æ–‡ä»¶æ ¼å¼è½¬æ¢å’Œå¤„ç†
- **é€‚ç”¨åœºæ™¯**ï¼šæ–‡æ¡£è½¬æ¢ã€æ‰¹é‡å¤„ç†ã€æ ¼å¼æ ‡å‡†åŒ–

```go
type FileProcessorAgentConfig struct {
    MaxSteps        int      `json:"max_steps"`
    SupportedTypes  []string `json:"supported_types"`
    OutputFormats   []string `json:"output_formats"`
    CompressionLevel int     `json:"compression_level"`
}
```

### è‡ªå®šä¹‰Agentç±»å‹

```go
// åˆ›å»ºè‡ªå®šä¹‰Agentç±»å‹
type CustomAgent struct {
    *agent.BaseAgent
    specialConfig *CustomConfig
}

func NewCustomAgent(config *CustomConfig) *CustomAgent {
    baseAgent := agent.NewBaseAgent(
        llmClient,
        toolRegistry,
        stateStore,
    )
    
    return &CustomAgent{
        BaseAgent:     baseAgent,
        specialConfig: config,
    }
}

func (a *CustomAgent) Plan(ctx context.Context, goal string, trace *state.Trace) (*state.Action, error) {
    // è‡ªå®šä¹‰è§„åˆ’é€»è¾‘
    // å¯ä»¥æ ¹æ®ç‰¹å®šé¢†åŸŸçŸ¥è¯†è°ƒæ•´è§„åˆ’ç­–ç•¥
    return a.customPlan(ctx, goal, trace)
}

// æ³¨å†Œè‡ªå®šä¹‰Agentç±»å‹
func (f *AgentFactory) CreateAgent(agentType string, config map[string]interface{}) (agent.Agent, error) {
    switch agentType {
    case "custom_agent":
        return f.createCustomAgent(config)
    case "ml_specialist":
        return f.createMLSpecialistAgent(config)
    default:
        return f.createGeneralAgent(config)
    }
}
```

## ğŸ“¡ äº‹ä»¶ç³»ç»Ÿ

### äº‹ä»¶ç±»å‹

```go
type EventType string

const (
    EventFlowStarted    EventType = "flow_started"
    EventFlowCompleted  EventType = "flow_completed"
    EventFlowFailed     EventType = "flow_failed"
    EventTaskStarted    EventType = "task_started"
    EventTaskCompleted  EventType = "task_completed"
    EventTaskFailed     EventType = "task_failed"
    EventTaskSkipped    EventType = "task_skipped"
    EventAgentCreated   EventType = "agent_created"
    EventAgentDestroyed EventType = "agent_destroyed"
)

type Event struct {
    ID          string                 `json:"id"`
    Type        EventType              `json:"type"`
    Timestamp   time.Time              `json:"timestamp"`
    WorkflowID  string                 `json:"workflow_id"`
    TaskID      string                 `json:"task_id,omitempty"`
    AgentID     string                 `json:"agent_id,omitempty"`
    Message     string                 `json:"message"`
    Data        map[string]interface{} `json:"data,omitempty"`
    Error       string                 `json:"error,omitempty"`
}
```

### äº‹ä»¶ç›‘å¬

```go
// ç›‘å¬å·¥ä½œæµäº‹ä»¶
func monitorWorkflow(engine *flow.Engine, workflowID string) {
    eventChan, unsubscribe := engine.Subscribe(workflowID)
    defer unsubscribe()
    
    for event := range eventChan {
        switch event.Type {
        case flow.EventFlowStarted:
            log.Printf("ğŸš€ å·¥ä½œæµå¼€å§‹: %s", event.Message)
            
        case flow.EventTaskStarted:
            log.Printf("ğŸ”„ ä»»åŠ¡å¼€å§‹: %s (ID: %s)", event.Message, event.TaskID)
            
        case flow.EventTaskCompleted:
            duration := event.Data["duration"].(time.Duration)
            log.Printf("âœ… ä»»åŠ¡å®Œæˆ: %s (è€—æ—¶: %v)", event.Message, duration)
            
        case flow.EventTaskFailed:
            log.Printf("âŒ ä»»åŠ¡å¤±è´¥: %s (é”™è¯¯: %s)", event.Message, event.Error)
            
        case flow.EventFlowCompleted:
            totalDuration := event.Data["total_duration"].(time.Duration)
            log.Printf("ğŸ‰ å·¥ä½œæµå®Œæˆ: %s (æ€»è€—æ—¶: %v)", event.Message, totalDuration)
            
        case flow.EventFlowFailed:
            log.Printf("ğŸ’¥ å·¥ä½œæµå¤±è´¥: %s (é”™è¯¯: %s)", event.Message, event.Error)
        }
    }
}
```

### äº‹ä»¶å¤„ç†å™¨

```go
// è‡ªå®šä¹‰äº‹ä»¶å¤„ç†å™¨
type WorkflowEventHandler struct {
    notifier *NotificationService
    metrics  *MetricsCollector
}

func (h *WorkflowEventHandler) HandleEvent(event *flow.Event) {
    // è®°å½•æŒ‡æ ‡
    h.metrics.RecordEvent(event)
    
    // å‘é€é€šçŸ¥
    switch event.Type {
    case flow.EventFlowCompleted:
        h.notifier.SendSuccess(event.WorkflowID, event.Message)
    case flow.EventFlowFailed:
        h.notifier.SendAlert(event.WorkflowID, event.Error)
    case flow.EventTaskFailed:
        h.notifier.SendWarning(event.TaskID, event.Error)
    }
    
    // è‡ªåŠ¨æ¢å¤ç­–ç•¥
    if event.Type == flow.EventTaskFailed {
        h.handleTaskFailure(event)
    }
}

func (h *WorkflowEventHandler) handleTaskFailure(event *flow.Event) {
    taskConfig := h.getTaskConfig(event.TaskID)
    
    if taskConfig.AutoRetry && taskConfig.RetryCount < taskConfig.MaxRetries {
        // è‡ªåŠ¨é‡è¯•å¤±è´¥çš„ä»»åŠ¡
        h.retryTask(event.TaskID)
    }
}
```

## ğŸ”§ å®é™…åº”ç”¨

### ç¤ºä¾‹1ï¼šç”µå•†æ•°æ®åˆ†ææµæ°´çº¿

```go
func createEcommerceAnalysisPipeline() *flow.Workflow {
    workflow := flow.NewWorkflow(
        "ecommerce-analysis",
        "ç”µå•†æ•°æ®åˆ†ææµæ°´çº¿",
        flow.ExecutionModeDAG,
    )
    
    // 1. æ•°æ®æ”¶é›†ï¼ˆå¹¶è¡Œï¼‰
    salesDataTask := flow.NewTask("sales-data", "é”€å”®æ•°æ®æ”¶é›†", "web_scraper",
        "ä»é”€å”®ç³»ç»ŸAPIæ”¶é›†äº¤æ˜“æ•°æ®")
    salesDataTask.Input = map[string]any{
        "api_endpoint": "https://sales-api.company.com/transactions",
        "date_range": "last_30_days",
    }
    
    userDataTask := flow.NewTask("user-data", "ç”¨æˆ·æ•°æ®æ”¶é›†", "web_scraper",
        "ä»ç”¨æˆ·ç®¡ç†ç³»ç»Ÿæ”¶é›†ç”¨æˆ·è¡Œä¸ºæ•°æ®")
    userDataTask.Input = map[string]any{
        "api_endpoint": "https://user-api.company.com/behaviors",
        "date_range": "last_30_days",
    }
    
    productDataTask := flow.NewTask("product-data", "äº§å“æ•°æ®æ”¶é›†", "web_scraper",
        "ä»äº§å“ç›®å½•ç³»ç»Ÿæ”¶é›†äº§å“ä¿¡æ¯")
    productDataTask.Input = map[string]any{
        "api_endpoint": "https://catalog-api.company.com/products",
    }
    
    // 2. æ•°æ®æ•´åˆ
    dataIntegrationTask := flow.NewTask("integration", "æ•°æ®æ•´åˆ", "data_analysis",
        "æ•´åˆæ¥è‡ªä¸åŒæºçš„æ•°æ®ï¼Œå»ºç«‹å…³è”å…³ç³»")
    dataIntegrationTask.Dependencies = []string{"sales-data", "user-data", "product-data"}
    dataIntegrationTask.Input = map[string]any{
        "join_keys": []string{"user_id", "product_id"},
        "output_format": "parquet",
    }
    
    // 3. æ•°æ®åˆ†æï¼ˆå¹¶è¡Œï¼‰
    salesAnalysisTask := flow.NewTask("sales-analysis", "é”€å”®åˆ†æ", "data_analysis",
        "åˆ†æé”€å”®è¶‹åŠ¿å’Œæ¨¡å¼")
    salesAnalysisTask.Dependencies = []string{"integration"}
    
    userAnalysisTask := flow.NewTask("user-analysis", "ç”¨æˆ·åˆ†æ", "data_analysis",
        "åˆ†æç”¨æˆ·è¡Œä¸ºå’Œåå¥½")
    userAnalysisTask.Dependencies = []string{"integration"}
    
    productAnalysisTask := flow.NewTask("product-analysis", "äº§å“åˆ†æ", "data_analysis",
        "åˆ†æäº§å“æ€§èƒ½å’Œçƒ­åº¦")
    productAnalysisTask.Dependencies = []string{"integration"}
    
    // 4. æŠ¥å‘Šç”Ÿæˆ
    reportTask := flow.NewTask("report", "ç»¼åˆæŠ¥å‘Šç”Ÿæˆ", "file_processor",
        "ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Šå’Œå¯è§†åŒ–ä»ªè¡¨æ¿")
    reportTask.Dependencies = []string{"sales-analysis", "user-analysis", "product-analysis"}
    reportTask.Input = map[string]any{
        "template": "ecommerce_report_template.html",
        "output_formats": []string{"pdf", "html"},
        "include_charts": true,
    }
    
    // 5. ç»“æœåˆ†å‘
    distributionTask := flow.NewTask("distribution", "ç»“æœåˆ†å‘", "general",
        "å°†æŠ¥å‘Šå‘é€ç»™ç›¸å…³å›¢é˜Ÿ")
    distributionTask.Dependencies = []string{"report"}
    distributionTask.Input = map[string]any{
        "recipients": []string{
            "sales-team@company.com",
            "marketing-team@company.com",
            "product-team@company.com",
        },
        "notification_channels": []string{"email", "slack"},
    }
    
    workflow.AddTask(salesDataTask)
    workflow.AddTask(userDataTask)
    workflow.AddTask(productDataTask)
    workflow.AddTask(dataIntegrationTask)
    workflow.AddTask(salesAnalysisTask)
    workflow.AddTask(userAnalysisTask)
    workflow.AddTask(productAnalysisTask)
    workflow.AddTask(reportTask)
    workflow.AddTask(distributionTask)
    
    return workflow
}
```

### ç¤ºä¾‹2ï¼šå†…å®¹ç®¡ç†ç³»ç»Ÿ

```bash
# å¯åŠ¨å†…å®¹ç®¡ç†å·¥ä½œæµ
./bin/openmanus flow --workflow examples/content-management.json
```

`content-management.json`:
```json
{
  "id": "content-management",
  "name": "å†…å®¹ç®¡ç†å·¥ä½œæµ",
  "mode": "dag",
  "tasks": [
    {
      "id": "content-scan",
      "name": "å†…å®¹æ‰«æ",
      "agent_type": "file_processor",
      "goal": "æ‰«æcontentç›®å½•ï¼Œè¯†åˆ«æ–°å¢å’Œä¿®æ”¹çš„æ–‡ä»¶",
      "dependencies": [],
      "input": {
        "scan_directory": "./content",
        "file_types": ["*.md", "*.html", "*.txt"],
        "since": "last_run"
      }
    },
    {
      "id": "content-analysis",
      "name": "å†…å®¹åˆ†æ",
      "agent_type": "data_analysis",
      "goal": "åˆ†æå†…å®¹è´¨é‡ã€å…³é”®è¯å’ŒSEOæŒ‡æ ‡",
      "dependencies": ["content-scan"],
      "input": {
        "analysis_types": ["readability", "seo", "sentiment"],
        "language": "zh-CN"
      }
    },
    {
      "id": "image-optimization",
      "name": "å›¾ç‰‡ä¼˜åŒ–",
      "agent_type": "file_processor",
      "goal": "ä¼˜åŒ–å›¾ç‰‡å¤§å°å’Œæ ¼å¼",
      "dependencies": ["content-scan"],
      "input": {
        "image_quality": 85,
        "formats": ["webp", "jpg"],
        "max_width": 1920
      }
    },
    {
      "id": "static-generation",
      "name": "é™æ€æ–‡ä»¶ç”Ÿæˆ",
      "agent_type": "file_processor",
      "goal": "ç”Ÿæˆé™æ€ç½‘ç«™æ–‡ä»¶",
      "dependencies": ["content-analysis", "image-optimization"],
      "input": {
        "template_engine": "hugo",
        "output_directory": "./public",
        "minify": true
      }
    },
    {
      "id": "deployment",
      "name": "éƒ¨ç½²å‘å¸ƒ",
      "agent_type": "general",
      "goal": "å°†ç”Ÿæˆçš„æ–‡ä»¶éƒ¨ç½²åˆ°CDN",
      "dependencies": ["static-generation"],
      "input": {
        "cdn_provider": "cloudflare",
        "cache_invalidation": true
      }
    }
  ]
}
```

### ç¤ºä¾‹3ï¼šç³»ç»Ÿç›‘æ§å’Œç»´æŠ¤

```go
func createSystemMaintenanceWorkflow() *flow.Workflow {
    workflow := flow.NewWorkflow(
        "system-maintenance",
        "ç³»ç»Ÿç»´æŠ¤å·¥ä½œæµ",
        flow.ExecutionModeSequential, // ç»´æŠ¤ä»»åŠ¡éœ€è¦é¡ºåºæ‰§è¡Œ
    )
    
    // 1. ç³»ç»Ÿå¥åº·æ£€æŸ¥
    healthCheckTask := flow.NewTask("health-check", "ç³»ç»Ÿå¥åº·æ£€æŸ¥", "general",
        "æ£€æŸ¥ç³»ç»Ÿå„ç»„ä»¶çš„è¿è¡ŒçŠ¶æ€")
    healthCheckTask.Input = map[string]any{
        "services": []string{"nginx", "redis", "mysql", "app"},
        "check_disk_space": true,
        "check_memory_usage": true,
        "check_cpu_load": true,
    }
    
    // 2. æ—¥å¿—æ¸…ç†
    logCleanupTask := flow.NewTask("log-cleanup", "æ—¥å¿—æ¸…ç†", "file_processor",
        "æ¸…ç†è¿‡æœŸçš„æ—¥å¿—æ–‡ä»¶")
    logCleanupTask.Dependencies = []string{"health-check"}
    logCleanupTask.Input = map[string]any{
        "log_directories": []string{"/var/log", "./logs"},
        "retention_days": 30,
        "compress_old_logs": true,
    }
    
    // 3. æ•°æ®åº“ç»´æŠ¤
    dbMaintenanceTask := flow.NewTask("db-maintenance", "æ•°æ®åº“ç»´æŠ¤", "data_analysis",
        "æ‰§è¡Œæ•°æ®åº“ä¼˜åŒ–å’Œæ¸…ç†")
    dbMaintenanceTask.Dependencies = []string{"log-cleanup"}
    dbMaintenanceTask.Input = map[string]any{
        "operations": []string{
            "analyze_tables",
            "optimize_tables",
            "clean_temp_data",
        },
        "databases": []string{"main", "analytics"},
    }
    
    // 4. å¤‡ä»½æ£€æŸ¥
    backupCheckTask := flow.NewTask("backup-check", "å¤‡ä»½æ£€æŸ¥", "general",
        "éªŒè¯å¤‡ä»½æ–‡ä»¶çš„å®Œæ•´æ€§")
    backupCheckTask.Dependencies = []string{"db-maintenance"}
    backupCheckTask.Input = map[string]any{
        "backup_locations": []string{"/backup", "s3://backup-bucket"},
        "verify_integrity": true,
        "test_restore": false, // åœ¨æµ‹è¯•ç¯å¢ƒä¸­å¯ä»¥è®¾ä¸ºtrue
    }
    
    // 5. ç»´æŠ¤æŠ¥å‘Š
    reportTask := flow.NewTask("maintenance-report", "ç»´æŠ¤æŠ¥å‘Š", "file_processor",
        "ç”Ÿæˆç³»ç»Ÿç»´æŠ¤æŠ¥å‘Š")
    reportTask.Dependencies = []string{"backup-check"}
    reportTask.Input = map[string]any{
        "report_template": "maintenance_report.md",
        "include_metrics": true,
        "send_email": true,
        "recipients": ["admin@company.com"],
    }
    
    workflow.AddTask(healthCheckTask)
    workflow.AddTask(logCleanupTask)
    workflow.AddTask(dbMaintenanceTask)
    workflow.AddTask(backupCheckTask)
    workflow.AddTask(reportTask)
    
    return workflow
}
```

## âš¡ æ€§èƒ½ä¼˜åŒ–

### å¹¶å‘æ§åˆ¶

```go
// é…ç½®æœ€å¤§å¹¶å‘æ•°
type FlowEngineConfig struct {
    MaxConcurrency   int           `json:"max_concurrency"`
    WorkerPoolSize   int           `json:"worker_pool_size"`
    TaskTimeout      time.Duration `json:"task_timeout"`
    QueueSize        int           `json:"queue_size"`
    ResourceLimits   ResourceLimits `json:"resource_limits"`
}

type ResourceLimits struct {
    MaxMemoryPerAgent string `json:"max_memory_per_agent"`
    MaxCPUPerAgent    string `json:"max_cpu_per_agent"`
    MaxDiskSpace      string `json:"max_disk_space"`
}
```

### èµ„æºæ± ç®¡ç†

```go
// Agentèµ„æºæ± 
type AgentPool struct {
    agents   map[string][]agent.Agent
    mutex    sync.RWMutex
    maxSize  int
    factory  *AgentFactory
}

func (p *AgentPool) GetAgent(agentType string) agent.Agent {
    p.mutex.Lock()
    defer p.mutex.Unlock()
    
    agents := p.agents[agentType]
    if len(agents) > 0 {
        // å¤ç”¨ç°æœ‰Agent
        agent := agents[len(agents)-1]
        p.agents[agentType] = agents[:len(agents)-1]
        return agent
    }
    
    // åˆ›å»ºæ–°Agent
    return p.factory.CreateAgent(agentType, nil)
}

func (p *AgentPool) ReturnAgent(agentType string, agent agent.Agent) {
    p.mutex.Lock()
    defer p.mutex.Unlock()
    
    agents := p.agents[agentType]
    if len(agents) < p.maxSize {
        p.agents[agentType] = append(agents, agent)
    } else {
        // æ± å·²æ»¡ï¼Œé”€æ¯Agent
        agent.Stop()
    }
}
```

### ç¼“å­˜ç­–ç•¥

```go
// ç»“æœç¼“å­˜
type ResultCache struct {
    cache  map[string]CacheEntry
    mutex  sync.RWMutex
    maxAge time.Duration
}

type CacheEntry struct {
    Result    interface{}
    Timestamp time.Time
    Hash      string
}

func (c *ResultCache) Get(taskID string, inputHash string) (interface{}, bool) {
    c.mutex.RLock()
    defer c.mutex.RUnlock()
    
    entry, exists := c.cache[taskID]
    if !exists {
        return nil, false
    }
    
    // æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
    if time.Since(entry.Timestamp) > c.maxAge {
        delete(c.cache, taskID)
        return nil, false
    }
    
    // æ£€æŸ¥è¾“å…¥æ˜¯å¦ç›¸åŒ
    if entry.Hash != inputHash {
        return nil, false
    }
    
    return entry.Result, true
}
```

### ç›‘æ§å’ŒæŒ‡æ ‡

```go
// å·¥ä½œæµæŒ‡æ ‡
type WorkflowMetrics struct {
    TotalExecutions    int64         `json:"total_executions"`
    SuccessfulRuns     int64         `json:"successful_runs"`
    FailedRuns         int64         `json:"failed_runs"`
    AverageExecutionTime time.Duration `json:"average_execution_time"`
    TaskMetrics        map[string]TaskMetric `json:"task_metrics"`
}

type TaskMetric struct {
    ExecutionCount   int64         `json:"execution_count"`
    SuccessRate      float64       `json:"success_rate"`
    AverageTime      time.Duration `json:"average_time"`
    ErrorTypes       map[string]int `json:"error_types"`
}

// æ”¶é›†æŒ‡æ ‡
func (e *FlowEngine) collectMetrics(execution *WorkflowExecution) {
    e.metrics.TotalExecutions++
    
    if execution.Status == StatusCompleted {
        e.metrics.SuccessfulRuns++
    } else {
        e.metrics.FailedRuns++
    }
    
    duration := execution.EndTime.Sub(execution.StartTime)
    e.updateAverageExecutionTime(duration)
    
    // æ›´æ–°ä»»åŠ¡æŒ‡æ ‡
    for _, taskResult := range execution.TaskResults {
        e.updateTaskMetrics(taskResult)
    }
}
```

### æœ€ä½³å®è·µ

1. **åˆç†è®¾ç½®å¹¶å‘æ•°**ï¼š
   - æ ¹æ®ç³»ç»Ÿèµ„æºè°ƒæ•´`max_concurrency`
   - ç›‘æ§CPUå’Œå†…å­˜ä½¿ç”¨ç‡
   - é¿å…è¿‡åº¦å¹¶å‘å¯¼è‡´èµ„æºç«äº‰

2. **ä¼˜åŒ–ä»»åŠ¡ä¾èµ–**ï¼š
   - æœ€å°åŒ–ä¸å¿…è¦çš„ä¾èµ–å…³ç³»
   - å°†ç‹¬ç«‹ä»»åŠ¡è®¾ä¸ºå¹¶è¡Œæ‰§è¡Œ
   - ä½¿ç”¨DAGæ¨¡å¼è·å¾—æœ€ä¼˜æ‰§è¡Œè·¯å¾„

3. **é”™è¯¯å¤„ç†ç­–ç•¥**ï¼š
   - è®¾ç½®åˆç†çš„é‡è¯•æ¬¡æ•°å’Œé—´éš”
   - å®ç°ä¼˜é›…é™çº§æœºåˆ¶
   - è®°å½•è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ç”¨äºè°ƒè¯•

4. **èµ„æºç®¡ç†**ï¼š
   - ä½¿ç”¨Agentæ± å‡å°‘åˆ›å»ºå¼€é”€
   - å®ç°ç»“æœç¼“å­˜æé«˜æ•ˆç‡
   - è®¾ç½®è¶…æ—¶é¿å…æ— é™ç­‰å¾…

5. **ç›‘æ§å’Œå‘Šè­¦**ï¼š
   - ç›‘æ§å·¥ä½œæµæ‰§è¡ŒçŠ¶æ€
   - è®¾ç½®å…³é”®æŒ‡æ ‡å‘Šè­¦
   - å®šæœŸåˆ†ææ€§èƒ½ç“¶é¢ˆ

---

é€šè¿‡å¤šAgentåä½œï¼ŒOpenManus-Go å¯ä»¥å¤„ç†å¤æ‚çš„ä¸šåŠ¡æµç¨‹ï¼Œæä¾›å¼ºå¤§çš„ä»»åŠ¡ç¼–æ’å’Œåè°ƒèƒ½åŠ›ã€‚åˆç†çš„è®¾è®¡å’Œä¼˜åŒ–å¯ä»¥å¤§å¤§æé«˜ç³»ç»Ÿçš„æ•ˆç‡å’Œå¯é æ€§ï¼

**ç›¸å…³æ–‡æ¡£**: [æ ¸å¿ƒæ¦‚å¿µ](CONCEPTS.md) â†’ [ä½¿ç”¨ç¤ºä¾‹](EXAMPLES.md) â†’ [æ€§èƒ½ä¼˜åŒ–](PERFORMANCE.md)
